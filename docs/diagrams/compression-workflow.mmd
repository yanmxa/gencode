%% Session Compression - Complete Workflow
%% From user input to LLM response

flowchart TD
    Start([User Input]) --> AddToAgent[Agent adds message]
    AddToAgent --> CallSM[SessionManager.addMessage<br/>with modelInfo]

    CallSM --> PushMsg[Push to messages array]
    PushMsg --> UpdateCount[Update fullMessageCount]
    UpdateCount --> CheckCompress{Needs compression?<br/>needsCompression}

    CheckCompress -->|No| SaveSession[Save session]
    CheckCompress -->|Yes| DetermineStrategy{Determine strategy}

    DetermineStrategy -->|prune| Layer1[Layer 1: Pruning]
    DetermineStrategy -->|compact| Layer2[Layer 2: Compaction]

    %% Layer 1 detailed flow
    Layer1 --> EstTokens1[Estimate total tokens]
    EstTokens1 --> CollectRecent[Collect recent tool outputs<br/>within last 40k tokens<br/>backward iteration]
    CollectRecent --> MarkProtected[Mark as protected indices]
    MarkProtected --> ClearOld[Clear unprotected<br/>old tool results]
    ClearOld --> MarkPruned[Mark: Old tool result cleared<br/>pruned: true<br/>prunedAt: timestamp]
    MarkPruned --> SaveSession

    %% Layer 2 detailed flow
    Layer2 --> DetermineRange[Determine summary range<br/>start: after last summary<br/>end: length - 10]
    DetermineRange --> ExtractInfo[Extract structured info in parallel]

    ExtractInfo --> Files[Files modified<br/>Write/Edit tools]
    ExtractInfo --> Tools[Tool usage stats<br/>count + top 3 uses]
    ExtractInfo --> Decisions[Key decisions<br/>decided/chose/will use]

    Files --> GenPrompt[Generate continuation prompt]
    Tools --> GenPrompt
    Decisions --> GenPrompt

    GenPrompt --> LLMCall[Call LLM<br/>max_tokens: 1500<br/>generate continuation prompt]
    LLMCall --> CreateSummary[Create ConversationSummary<br/>id, range, content, metadata]
    CreateSummary --> StoreSummary[Store to session.summaries array]
    StoreSummary --> ReplaceMessages[Replace messages array]

    ReplaceMessages --> BuildNew[Build new messages array:<br/>System prompt<br/>Summary system message<br/>Last 10 messages]
    BuildNew --> SaveSession

    SaveSession --> GetContext[Get LLM context<br/>getMessagesForLLM]
    GetContext --> AgentContinue[Agent continues<br/>call provider.complete]
    AgentContinue --> LLMResponse[LLM returns response]
    LLMResponse --> End([Done])

    style Layer1 fill:#ffd93d,stroke:#333,stroke-width:2px
    style Layer2 fill:#74c0fc,stroke:#333,stroke-width:2px
    style LLMCall fill:#ff6b6b,stroke:#333,stroke-width:2px
    style GetContext fill:#51cf66,stroke:#333,stroke-width:2px
